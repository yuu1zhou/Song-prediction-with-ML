{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from variable_share import y\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe403d6",
   "metadata": {},
   "source": [
    "We first picked a sample song to explore the avaliable acoustic features for song clustering. Since all the acoustic information for a song is stored in the 'analysis' branch, we examined only the 'analysis' part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2e2728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bars_confidence': <HDF5 dataset \"bars_confidence\": shape (1000,), type \"<f8\">,\n",
       " 'bars_start': <HDF5 dataset \"bars_start\": shape (1000,), type \"<f8\">,\n",
       " 'beats_confidence': <HDF5 dataset \"beats_confidence\": shape (1000,), type \"<f8\">,\n",
       " 'beats_start': <HDF5 dataset \"beats_start\": shape (1000,), type \"<f8\">,\n",
       " 'sections_confidence': <HDF5 dataset \"sections_confidence\": shape (14,), type \"<f8\">,\n",
       " 'sections_start': <HDF5 dataset \"sections_start\": shape (14,), type \"<f8\">,\n",
       " 'segments_confidence': <HDF5 dataset \"segments_confidence\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_max': <HDF5 dataset \"segments_loudness_max\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_max_time': <HDF5 dataset \"segments_loudness_max_time\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_start': <HDF5 dataset \"segments_loudness_start\": shape (1506,), type \"<f8\">,\n",
       " 'segments_pitches': <HDF5 dataset \"segments_pitches\": shape (1506, 12), type \"<f8\">,\n",
       " 'segments_start': <HDF5 dataset \"segments_start\": shape (1506,), type \"<f8\">,\n",
       " 'segments_timbre': <HDF5 dataset \"segments_timbre\": shape (1506, 12), type \"<f8\">,\n",
       " 'songs': <HDF5 dataset \"songs\": shape (1,), type \"|V220\">,\n",
       " 'tatums_confidence': <HDF5 dataset \"tatums_confidence\": shape (2000,), type \"<f8\">,\n",
       " 'tatums_start': <HDF5 dataset \"tatums_start\": shape (2000,), type \"<f8\">}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:/songdata/MillionSongSubset/A/O/G/TRAOGTM128F931FABE.h5'\n",
    "f = h5py.File(path, 'r')\n",
    "\n",
    "dict(f['analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963ca8e",
   "metadata": {},
   "source": [
    "Feature names ending with '_confidence' represent the detection accuracy of the algorithm, ranging from 0 to 1, where a higher value indicates more reliable information. Here for convenience, we assumed that all acoustic feature-related confidence scores were generally reliable. Most of the acoustic features are stored in a 1-D array format, except for pitch- and timbre-related features, which are in a 2-D array format. While we acknowledge that these are important attributes of a song, we dropped them two to maintain alignment in the training data.\n",
    "\n",
    "After exploring the sample song, we proceeded to extract data for all 10,000 songs. And as mentioned in the 'draft', we needed to calculate relevant summary statistics for each acoustic feature and then perform clustering based on them. We wrote a reusable function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f8e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"D:/songdata/MillionSongSubset\"\n",
    "\n",
    "def read_from_filepaths(directory, feature_name): #create a list containing each song's specific acoustic feature array \n",
    "    file_paths = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.h5'):\n",
    "                file_paths.append(dirpath+'/'+filename)\n",
    "\n",
    "    file_paths = [file_path.replace('\\\\', '/') for file_path in file_paths] # filepath of all the songs\n",
    "\n",
    "    acoustic_feature_lis = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        acoustic_feature_lis.append(np.array(file['analysis'][feature_name]))\n",
    "    \n",
    "    return acoustic_feature_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b1d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_stats(x): # statistics: mean, standard deviation, interquantile range, coefficient of variation, skewness, kurtosis, quantile, length\n",
    "    x = np.asarray(x)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return np.array([np.nan]*10)\n",
    "    q10, q50, q90 = np.percentile(x, [10,50,90])\n",
    "    iqr = np.percentile(x, 75) - np.percentile(x, 25)\n",
    "    cv = np.std(x) / (np.mean(x)+1e-8)\n",
    "\n",
    "    return np.array([np.mean(x), np.std(x), iqr, cv, skew(x), kurtosis(x), q10, q50, q90, len(x)])\n",
    "\n",
    "\n",
    "def hist_feat(x, bins=20): #instance number in each bin, we set 20 bins\n",
    "    if len(x)==0: return np.zeros(bins)\n",
    "    h, _ = np.histogram(x, bins=bins, density=True)\n",
    "    return h\n",
    "\n",
    "def cal_stat_matrix(acoustic_array): # create matrix whose columns are all summary statistics\n",
    "    rows = []\n",
    "\n",
    "    for b in acoustic_array:  # list[np.ndarray]\n",
    "        if b is None or len(b)<2:\n",
    "            rows.append(np.zeros(10+20))  # 占位\n",
    "            continue\n",
    "        \n",
    "        d = np.diff(b)\n",
    "        d = d[d>0]\n",
    "        if d.size == 0:\n",
    "            rows.append(np.zeros(10+20))\n",
    "            continue\n",
    "        d = d / (np.median(d)+1e-8)\n",
    "        rows.append(np.concatenate([seq_stats(d), hist_feat(d, bins=20)])) # 30 summary statistics in total\n",
    "\n",
    "    X_stat = np.vstack(rows)  # (n_songs, ~30)\n",
    "    X_stat = np.nan_to_num(X_stat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8e153",
   "metadata": {},
   "source": [
    "After obtaining the statistics matrix, we performed K-Means clustering. The reusable function is shown below, and we used MiniBatchKMeans to speed up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2faea847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cluster_oof_features(X_stats, y, k=32, n_splits=5): # cluster number\n",
    "    n = len(y)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_dist  = np.zeros((n, k)) # distance to core of each cluster, each song\n",
    "    oof_label = np.zeros(n, dtype=int) # cluster label, each song\n",
    "\n",
    "    for tr, va in kf.split(X_stats): # training, validation sets\n",
    "        scaler = StandardScaler().fit(X_stats[tr])\n",
    "        Xz_tr = scaler.transform(X_stats[tr])\n",
    "        Xz_va = scaler.transform(X_stats[va])\n",
    "\n",
    "        km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=2048, n_init=\"auto\").fit(Xz_tr)\n",
    "\n",
    "        oof_dist[va]  = km.transform(Xz_va)  \n",
    "        oof_label[va] = km.predict(Xz_va)\n",
    "\n",
    "    return (oof_dist, oof_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438693b",
   "metadata": {},
   "source": [
    "# Song acoutic feature\n",
    "\n",
    "We then performed song clustering on a feature-by-feature basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9d3e6",
   "metadata": {},
   "source": [
    "## bars_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf7b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_array = read_from_filepaths(directory, \"bars_start\")\n",
    "X_stat = cal_stat_matrix(bar_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336d1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] 系统找不到指定的文件。\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\miniconda3\\envs\\pydata-book\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\miniconda3\\envs\\pydata-book\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"d:\\miniconda3\\envs\\pydata-book\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "array_cluster_bars = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7a350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_cluster_bars[0].shape, array_cluster_bars[1].shape #the distance of a song to each cluster core + clustering label predicted from validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065218b0",
   "metadata": {},
   "source": [
    "## beats_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfcf1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_array = read_from_filepaths(directory, \"beats_start\")\n",
    "X_stat = cal_stat_matrix(beat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0163a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "array_cluster_beats = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e355f",
   "metadata": {},
   "source": [
    "## sections_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ede7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_array = read_from_filepaths(directory, \"sections_start\")\n",
    "X_stat = cal_stat_matrix(section_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b1b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "array_cluster_sections = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d221164",
   "metadata": {},
   "source": [
    "## segments_loudness_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a757e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loudness_array = read_from_filepaths(directory, \"segments_loudness_max\")\n",
    "X_stat = cal_stat_matrix(loudness_array)\n",
    "\n",
    "array_cluster_loudness = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461680f7",
   "metadata": {},
   "source": [
    "## segments_loudness_max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68710b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loudness_time_array = read_from_filepaths(directory, \"segments_loudness_max_time\")\n",
    "X_stat = cal_stat_matrix(loudness_time_array)\n",
    "\n",
    "array_cluster_loudness_time = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423ee03",
   "metadata": {},
   "source": [
    "## segments_loudness_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec7ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loudness_start_array = read_from_filepaths(directory, \"segments_loudness_start\")\n",
    "X_stat = cal_stat_matrix(loudness_start_array)\n",
    "\n",
    "array_cluster_loudness_start = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a8a28",
   "metadata": {},
   "source": [
    "## segments_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b50d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "segments_start_array = read_from_filepaths(directory, \"segments_start\")\n",
    "X_stat = cal_stat_matrix(segments_start_array)\n",
    "\n",
    "array_cluster_segments_start = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42177ee0",
   "metadata": {},
   "source": [
    "## tatums_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99464c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuyuz\\AppData\\Local\\Temp\\ipykernel_13804\\3304920897.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  return np.array([np.mean(x), np.std(x), iqr, cv, skew(x), kurtosis(x), q10, q50, q90, len(x)])\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\numpy\\lib\\_histograms_impl.py:902: RuntimeWarning: divide by zero encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\numpy\\lib\\_histograms_impl.py:902: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tatums_start_array = read_from_filepaths(directory, \"tatums_start\")\n",
    "X_stat = cal_stat_matrix(tatums_start_array)\n",
    "\n",
    "array_cluster_tatums_start = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b614fab",
   "metadata": {},
   "source": [
    "In total, we used 8 acoustic features, each associated with a clustering label array, and we saved all of these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09f551d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_bars = array_cluster_bars[1].reshape(-1, 1)\n",
    "cluster_label_beats = array_cluster_beats[1].reshape(-1,1)\n",
    "cluster_label_loudness = array_cluster_loudness[1].reshape(-1, 1)\n",
    "cluster_label_loudness_time = array_cluster_loudness_time[1].reshape(-1, 1)\n",
    "\n",
    "cluster_label_sections = array_cluster_sections[1].reshape(-1, 1)\n",
    "cluster_label_loudness_start = array_cluster_loudness_start[1].reshape(-1,1)\n",
    "cluster_label_segments_start = array_cluster_segments_start[1].reshape(-1, 1)\n",
    "cluster_label_tatums_start = array_cluster_tatums_start[1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "045493d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cluster_label_bars\", cluster_label_bars)\n",
    "np.save(\"cluster_label_beats\", cluster_label_beats)\n",
    "np.save(\"cluster_label_loudness\", cluster_label_loudness)\n",
    "np.save(\"cluster_label_loudness_time\", cluster_label_loudness_time)\n",
    "\n",
    "np.save(\"cluster_label_sections\", cluster_label_sections)\n",
    "np.save(\"cluster_label_loudness_start\", cluster_label_loudness_start)\n",
    "np.save(\"cluster_label_segments_start\", cluster_label_segments_start)\n",
    "np.save(\"cluster_label_tatums_start\", cluster_label_tatums_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
