{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ea7dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from variable_share import y\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe403d6",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2e2728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bars_confidence': <HDF5 dataset \"bars_confidence\": shape (1000,), type \"<f8\">,\n",
       " 'bars_start': <HDF5 dataset \"bars_start\": shape (1000,), type \"<f8\">,\n",
       " 'beats_confidence': <HDF5 dataset \"beats_confidence\": shape (1000,), type \"<f8\">,\n",
       " 'beats_start': <HDF5 dataset \"beats_start\": shape (1000,), type \"<f8\">,\n",
       " 'sections_confidence': <HDF5 dataset \"sections_confidence\": shape (14,), type \"<f8\">,\n",
       " 'sections_start': <HDF5 dataset \"sections_start\": shape (14,), type \"<f8\">,\n",
       " 'segments_confidence': <HDF5 dataset \"segments_confidence\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_max': <HDF5 dataset \"segments_loudness_max\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_max_time': <HDF5 dataset \"segments_loudness_max_time\": shape (1506,), type \"<f8\">,\n",
       " 'segments_loudness_start': <HDF5 dataset \"segments_loudness_start\": shape (1506,), type \"<f8\">,\n",
       " 'segments_pitches': <HDF5 dataset \"segments_pitches\": shape (1506, 12), type \"<f8\">,\n",
       " 'segments_start': <HDF5 dataset \"segments_start\": shape (1506,), type \"<f8\">,\n",
       " 'segments_timbre': <HDF5 dataset \"segments_timbre\": shape (1506, 12), type \"<f8\">,\n",
       " 'songs': <HDF5 dataset \"songs\": shape (1,), type \"|V220\">,\n",
       " 'tatums_confidence': <HDF5 dataset \"tatums_confidence\": shape (2000,), type \"<f8\">,\n",
       " 'tatums_start': <HDF5 dataset \"tatums_start\": shape (2000,), type \"<f8\">}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:/songdata/MillionSongSubset/A/O/G/TRAOGTM128F931FABE.h5'\n",
    "f = h5py.File(path, 'r')\n",
    "\n",
    "dict(f['analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033fcd1",
   "metadata": {},
   "source": [
    "# File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a760eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"D:/songdata/MillionSongSubset\"\n",
    "\n",
    "file_paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(directory):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.h5'):\n",
    "            file_paths.append(dirpath+'/'+filename)\n",
    "\n",
    "file_paths = [file_path.replace('\\\\', '/') for file_path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09f8e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"D:/songdata/MillionSongSubset\"\n",
    "\n",
    "def read_from_filepaths(directory, feature_name):\n",
    "    file_paths = []\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.h5'):\n",
    "                file_paths.append(dirpath+'/'+filename)\n",
    "\n",
    "    file_paths = [file_path.replace('\\\\', '/') for file_path in file_paths]\n",
    "\n",
    "    acoustic_feature_lis = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        acoustic_feature_lis.append(np.array(file['analysis'][feature_name]))\n",
    "    \n",
    "    return acoustic_feature_lis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f69c6",
   "metadata": {},
   "source": [
    "# X_stat matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9604dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_array = []\n",
    "for file_path in file_paths:\n",
    "    file = h5py.File(file_path, 'r')\n",
    "    bar_array.append(np.array(file['analysis']['bars_start']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c706d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_stats(x):\n",
    "    x = np.asarray(x)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return np.array([np.nan]*10)\n",
    "    q10, q50, q90 = np.percentile(x, [10,50,90])\n",
    "    iqr = np.percentile(x, 75) - np.percentile(x, 25)\n",
    "    cv = np.std(x) / (np.mean(x)+1e-8)\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    return np.array([np.mean(x), np.std(x), iqr, cv, skew(x), kurtosis(x), q10, q50, q90, len(x)])\n",
    "\n",
    "\n",
    "def hist_feat(x, bins=20):\n",
    "    if len(x)==0: return np.zeros(bins)\n",
    "    h, _ = np.histogram(x, bins=bins, density=True)\n",
    "    return h\n",
    "\n",
    "rows = []\n",
    "for b in bar_array:  # list[np.ndarray]\n",
    "    if b is None or len(b)<2:\n",
    "        rows.append(np.zeros(10+20))  # 占位\n",
    "        continue\n",
    "    \n",
    "    d = np.diff(b)\n",
    "    d = d[d>0]\n",
    "    if d.size == 0:\n",
    "        rows.append(np.zeros(10+20))\n",
    "        continue\n",
    "    d = d / (np.median(d)+1e-8)\n",
    "    rows.append(np.concatenate([seq_stats(d), hist_feat(d, bins=20)])) #总共 30 个 statistics\n",
    "\n",
    "X_stat = np.vstack(rows)  # (n_songs, ~30)\n",
    "X_stat = np.nan_to_num(X_stat, nan=0.0, posinf=0.0, neginf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_stats(x):\n",
    "    x = np.asarray(x)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return np.array([np.nan]*10)\n",
    "    q10, q50, q90 = np.percentile(x, [10,50,90])\n",
    "    iqr = np.percentile(x, 75) - np.percentile(x, 25)\n",
    "    cv = np.std(x) / (np.mean(x)+1e-8)\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    return np.array([np.mean(x), np.std(x), iqr, cv, skew(x), kurtosis(x), q10, q50, q90, len(x)])\n",
    "\n",
    "\n",
    "def hist_feat(x, bins=20):\n",
    "    if len(x)==0: return np.zeros(bins)\n",
    "    h, _ = np.histogram(x, bins=bins, density=True)\n",
    "    return h\n",
    "\n",
    "def cal_stat_matrix(acoustic_array):\n",
    "    rows = []\n",
    "\n",
    "    for b in acoustic_array:  # list[np.ndarray]\n",
    "        if b is None or len(b)<2:\n",
    "            rows.append(np.zeros(10+20))  # 占位\n",
    "            continue\n",
    "        \n",
    "        d = np.diff(b)\n",
    "        d = d[d>0]\n",
    "        if d.size == 0:\n",
    "            rows.append(np.zeros(10+20))\n",
    "            continue\n",
    "        d = d / (np.median(d)+1e-8)\n",
    "        rows.append(np.concatenate([seq_stats(d), hist_feat(d, bins=20)])) #总共 30 个 statistics\n",
    "\n",
    "    X_stat = np.vstack(rows)  # (n_songs, ~30)\n",
    "    X_stat = np.nan_to_num(X_stat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca6974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74dc7f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "543154dc-1896-48f4-8048-46ad082610f5",
       "rows": [
        [
         "0",
         "0"
        ],
        [
         "1",
         "0"
        ],
        [
         "2",
         "0"
        ],
        [
         "3",
         "0"
        ],
        [
         "4",
         "0"
        ],
        [
         "5",
         "0"
        ],
        [
         "6",
         "0"
        ],
        [
         "7",
         "0"
        ],
        [
         "8",
         "0"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "0"
        ],
        [
         "11",
         "0"
        ],
        [
         "12",
         "0"
        ],
        [
         "13",
         "0"
        ],
        [
         "14",
         "0"
        ],
        [
         "15",
         "0"
        ],
        [
         "16",
         "0"
        ],
        [
         "17",
         "0"
        ],
        [
         "18",
         "0"
        ],
        [
         "19",
         "0"
        ],
        [
         "20",
         "0"
        ],
        [
         "21",
         "0"
        ],
        [
         "22",
         "0"
        ],
        [
         "23",
         "0"
        ],
        [
         "24",
         "0"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "0"
        ],
        [
         "27",
         "0"
        ],
        [
         "28",
         "0"
        ],
        [
         "29",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 30
       }
      },
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_stat).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438693b",
   "metadata": {},
   "source": [
    "# Song acoutic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9d3e6",
   "metadata": {},
   "source": [
    "## bars start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ddf7b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_array = read_from_filepaths(directory, \"bars_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01940235",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stat = cal_stat_matrix(bar_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2faea847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cluster_oof_features(X_stats, y, k=32, n_splits=5, task=\"classification\"):\n",
    "    n = len(y)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_dist  = np.zeros((n, k)) # distance to core of each cluster, each song\n",
    "    oof_mean  = np.zeros((n, 1)) # mean, each song\n",
    "    oof_size  = np.zeros((n, 1)) # \n",
    "    oof_label = np.zeros(n, dtype=int) # cluster labrl, each song\n",
    "\n",
    "    # 为了在测试时使用：训练完后再用全量拟合一遍\n",
    "    #scaler_full = StandardScaler().fit(X_stats)\n",
    "    #Xz_full = scaler_full.transform(X_stats)\n",
    "    #km_full = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=2048, n_init=\"auto\").fit(Xz_full)\n",
    "\n",
    "    for tr, va in kf.split(X_stats): # training, validation sets\n",
    "        # 1) 该折的标准化 + 聚类只在训练折上拟合\n",
    "        scaler = StandardScaler().fit(X_stats[tr])\n",
    "        Xz_tr = scaler.transform(X_stats[tr])\n",
    "        Xz_va = scaler.transform(X_stats[va])\n",
    "\n",
    "        km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=2048, n_init=\"auto\").fit(Xz_tr)\n",
    "\n",
    "        # 2) 给验证折打特征\n",
    "        oof_dist[va]  = km.transform(Xz_va)        # 到质心距离（越小越近）\n",
    "        oof_label[va] = km.predict(Xz_va)\n",
    "\n",
    "        # 3) 只用训练折按簇统计目标\n",
    "        #lab_tr = km.predict(Xz_tr)\n",
    "        #mean_by_c = {}  # 每一个cluster 的 mean\n",
    "        #size_by_c = {} # 每一个cluster 的 size\n",
    "        #base = y[tr].mean()\n",
    "        #for c in range(k):\n",
    "        #    mask = (lab_tr == c) \n",
    "        #    size = int(mask.sum())\n",
    "        #    size_by_c[c] = size #每一个 label 的 size, training set\n",
    "        #    if size > 0:\n",
    "        #        m = y[tr][mask].mean() if task == \"regression\" else y[tr][mask].mean()\n",
    "        #    else:\n",
    "        #        m = base\n",
    "        #    mean_by_c[c] = m\n",
    "\n",
    "        # 4) 把簇统计赋给验证折样本\n",
    "        #oof_mean[va, 0] = np.array([mean_by_c[c] for c in oof_label[va]])\n",
    "        #oof_size[va, 0] = np.array([size_by_c[c] for c in oof_label[va]])\n",
    "\n",
    "    # 供测试阶段：用全训练集的簇统计\n",
    "    #lab_full = km_full.predict(Xz_full)\n",
    "    #full_mean = {c: (y[lab_full==c].mean() if (lab_full==c).sum()>0 else y.mean()) for c in range(k)}\n",
    "    #full_size = {c: (lab_full==c).sum() for c in range(k)}\n",
    "\n",
    "    #cluster_stats_full = {\"mean\": full_mean, \"size\": full_size}\n",
    "\n",
    "    return (oof_dist, #oof_mean, oof_size, \n",
    "            oof_label,\n",
    "            #scaler_full, km_full, cluster_stats_full\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "336d1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "array_cluster_bars = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "79774643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_cluster_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9d7a350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32), (10000,))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_cluster_bars[0].shape, array_cluster_bars[1].shape # clustering label predicted from validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0e77472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_bars = np.concatenate((array_cluster_bars[0], array_cluster_bars[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_bars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065218b0",
   "metadata": {},
   "source": [
    "## Beat start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3bfcf1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_array = read_from_filepaths(directory, \"beats_start\")\n",
    "X_stat = cal_stat_matrix(beat_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0163a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "array_cluster_beats = build_cluster_oof_features(X_stat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a179736a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_beats = np.concatenate((array_cluster_beats[0], array_cluster_beats[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_beats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e355f",
   "metadata": {},
   "source": [
    "## Section start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0ede7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_array = read_from_filepaths(directory, \"sections_start\")\n",
    "X_stat = cal_stat_matrix(section_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "00b1b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_cluster_sections = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_sections = np.concatenate((array_cluster_sections[0], array_cluster_sections[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_sections.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d221164",
   "metadata": {},
   "source": [
    "## segments_loudness_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1a757e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness_array = read_from_filepaths(directory, \"segments_loudness_max\")\n",
    "X_stat = cal_stat_matrix(loudness_array)\n",
    "\n",
    "array_cluster_loudness = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_loudness = np.concatenate((array_cluster_loudness[0], array_cluster_loudness[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_loudness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461680f7",
   "metadata": {},
   "source": [
    "## segments_loudness_max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "68710b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness_time_array = read_from_filepaths(directory, \"segments_loudness_max_time\")\n",
    "X_stat = cal_stat_matrix(loudness_time_array)\n",
    "\n",
    "array_cluster_loudness_time = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_loudness_time = np.concatenate((array_cluster_loudness_time[0], array_cluster_loudness_time[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_loudness_time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423ee03",
   "metadata": {},
   "source": [
    "## segments_loudness_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness_start_array = read_from_filepaths(directory, \"segments_loudness_start\")\n",
    "X_stat = cal_stat_matrix(loudness_start_array)\n",
    "\n",
    "array_cluster_loudness_start = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_loudness_start = np.concatenate((array_cluster_loudness_start[0], array_cluster_loudness_start[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_loudness_start.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a8a28",
   "metadata": {},
   "source": [
    "## segments_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "94b50d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_start_array = read_from_filepaths(directory, \"segments_start\")\n",
    "X_stat = cal_stat_matrix(segments_start_array)\n",
    "\n",
    "array_cluster_segments_start = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_segments_start = np.concatenate((array_cluster_segments_start[0], array_cluster_segments_start[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_segments_start.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42177ee0",
   "metadata": {},
   "source": [
    "## tatums_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "99464c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n",
      "d:\\miniconda3\\envs\\pydata-book\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1952: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5632 or by setting the environment variable OMP_NUM_THREADS=8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tatums_start_array = read_from_filepaths(directory, \"tatums_start\")\n",
    "X_stat = cal_stat_matrix(tatums_start_array)\n",
    "\n",
    "array_cluster_tatums_start = build_cluster_oof_features(X_stat, y)\n",
    "\n",
    "combined_matrix_tatums_start = np.concatenate((array_cluster_tatums_start[0], array_cluster_tatums_start[1].reshape(-1,1)), axis=1) #final matrix but not standardized yet\n",
    "combined_matrix_tatums_start.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b614fab",
   "metadata": {},
   "source": [
    "# Matrix creeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb578b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 33), (10000, 33), (10000, 33), (10000, 33), (10000, 33))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_bars.shape, combined_matrix_beats.shape, combined_matrix_sections.shape,combined_matrix_loudness.shape, combined_matrix_loudness_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b429fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix_combiend = np.concatenate([combined_matrix_bars, combined_matrix_beats, combined_matrix_sections, combined_matrix_loudness, \n",
    "                                      combined_matrix_loudness_time\n",
    "                                      ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce71d1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 165)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matrix_combiend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c478605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"acoustic_features_part.npy\", all_matrix_combiend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72527f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "all_matrix_combiend = scaler.fit_transform(all_matrix_combiend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ff1ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"acoustic_features_standardized_part.npy\", all_matrix_combiend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae090a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972520c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "09f551d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_bars = array_cluster_bars[1].reshape(-1, 1)\n",
    "cluster_label_beats = array_cluster_beats[1].reshape(-1,1)\n",
    "cluster_label_loudness = array_cluster_loudness[1].reshape(-1, 1)\n",
    "cluster_label_loudness_time = array_cluster_loudness_time[1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "045493d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cluster_label_bars\", cluster_label_bars)\n",
    "np.save(\"cluster_label_beats\", cluster_label_beats)\n",
    "np.save(\"cluster_label_loudness\", cluster_label_loudness)\n",
    "np.save(\"cluster_label_loudness_time\", cluster_label_loudness_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "069cd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_distance_bars = array_cluster_bars[0]\n",
    "cluster_distance_beats = array_cluster_beats[0]\n",
    "cluster_distance_loudness = array_cluster_loudness[0]\n",
    "cluster_distance_loudness_time = array_cluster_loudness_time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7bd00e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cluster_distance_bars\", cluster_distance_bars)\n",
    "np.save(\"cluster_distance_beats\", cluster_distance_beats)\n",
    "np.save(\"cluster_distance_loudness\", cluster_distance_loudness)\n",
    "np.save(\"cluster_distance_loudness_time\", cluster_distance_loudness_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1073b7c",
   "metadata": {},
   "source": [
    "补后面的acoustic feature label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dfa17f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_sections = array_cluster_sections[1].reshape(-1, 1)\n",
    "cluster_label_loudness_start = array_cluster_loudness_start[1].reshape(-1,1)\n",
    "cluster_label_segments_start = array_cluster_segments_start[1].reshape(-1, 1)\n",
    "cluster_label_tatums_start = array_cluster_tatums_start[1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "85c5d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cluster_label_sections\", cluster_label_sections)\n",
    "np.save(\"cluster_label_loudness_start\", cluster_label_loudness_start)\n",
    "np.save(\"cluster_label_segments_start\", cluster_label_segments_start)\n",
    "np.save(\"cluster_label_tatums_start\", cluster_label_tatums_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
